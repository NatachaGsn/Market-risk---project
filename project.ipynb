{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fff28d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.integrate import cumulative_trapezoid as cumtrapz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f68b3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>5.621</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>5.424</td>\n",
       "      <td>-0.035047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>5.329</td>\n",
       "      <td>-0.017515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>5.224</td>\n",
       "      <td>-0.019704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>5.453</td>\n",
       "      <td>0.043836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>4.045</td>\n",
       "      <td>-0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>4.010</td>\n",
       "      <td>-0.008653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>3.938</td>\n",
       "      <td>-0.017955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>4.088</td>\n",
       "      <td>0.038090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>4.119</td>\n",
       "      <td>0.007583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  value    return\n",
       "0    2015-01-02  5.621       NaN\n",
       "1    2015-01-05  5.424 -0.035047\n",
       "2    2015-01-06  5.329 -0.017515\n",
       "3    2015-01-07  5.224 -0.019704\n",
       "4    2015-01-08  5.453  0.043836\n",
       "...         ...    ...       ...\n",
       "1018 2018-12-21  4.045 -0.001481\n",
       "1019 2018-12-24  4.010 -0.008653\n",
       "1020 2018-12-27  3.938 -0.017955\n",
       "1021 2018-12-28  4.088  0.038090\n",
       "1022 2018-12-31  4.119  0.007583\n",
       "\n",
       "[1023 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Natixis.csv\", sep = \";\")\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d/%m/%Y\")\n",
    "df.sort_values(\"date\", inplace = True)\n",
    "\n",
    "df[\"value\"] = (df[\"value\"].astype(str).str.replace(\",\", \".\", regex=False))\n",
    "df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "\n",
    "df[\"return\"] = df[\"value\"] / df[\"value\"].shift(1) - 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a1cd8",
   "metadata": {},
   "source": [
    "## Question A (Ex2, part of Q1 and of Q2 of TD1)\n",
    "\n",
    "**a** – From the time series of the daily prices of the stock Natixis between January 2015 and December 2016, provided with TD1, estimate a historical VaR on price returns at a one-day horizon for a given probability level (this probability is a parameter which must be changed easily). You must base your VaR on a non-parametric distribution (biweight Kernel, that is $K$ is the derivative of the logistic function $x \\mapsto \\frac{15}{16}(1-x^2)^2 \\mathbb{1}_{|x| \\leq 1}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45bb76f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     -0.035047\n",
       "2     -0.017515\n",
       "3     -0.019704\n",
       "4      0.043836\n",
       "5     -0.020723\n",
       "         ...   \n",
       "508   -0.008118\n",
       "509    0.000744\n",
       "510   -0.000186\n",
       "511   -0.009481\n",
       "512    0.006006\n",
       "Name: return, Length: 512, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015_2016 = df[df[\"date\"] < \"2017\"].dropna().loc[:, \"return\"]\n",
    "df_2015_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763e8f9",
   "metadata": {},
   "source": [
    "Ce qu'on a fait (tout à refaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bac20c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical VaR is for returns between 2015 and 2016 is :  -6.007630146624207 %\n",
      "There are -6.01 % chances to lose 1.0 % of the portfolio's value\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.99\n",
    "\n",
    "def Kde_VaR(df, alpha, bw=None):\n",
    "    # Fit KDE (Gaussian kernel)\n",
    "    kde = gaussian_kde(df, bw_method=bw)  # 'scott' by default\n",
    "\n",
    "    # Build a grid covering the tail well\n",
    "    mu, s = np.mean(df), np.std(df, ddof=1)\n",
    "    lo = min(df.min(), mu - 6*s)\n",
    "    hi = max(df.max(), mu + 6*s)\n",
    "    grid = np.linspace(lo, hi, 20001)\n",
    "\n",
    "    # PDF on grid and CDF by numerical integration (trapezoid)\n",
    "    pdf = kde(grid)\n",
    "    cdf = cumtrapz(pdf, grid, initial=0.0)\n",
    "    cdf = cdf / cdf[-1]  # normalize to 1\n",
    "\n",
    "    # α-quantile by interpolation of the CDF\n",
    "    q_alpha = np.interp(alpha, cdf, grid)\n",
    "\n",
    "    return -q_alpha\n",
    "\n",
    "kde_var = Kde_VaR(df_2015_2016, alpha)\n",
    "\n",
    "print(\"The empirical VaR is for returns between 2015 and 2016 is : \", kde_var*100, \"%\")\n",
    "print(\"There are\", round(kde_var*100, 2), \"% chances to lose\", round((1 - alpha)*100, 2), \"% of the portfolio's value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fbaba",
   "metadata": {},
   "source": [
    "### First step: Estimation of the kernel density \n",
    "$$\\hat{f}(x) = \\frac{1}{nh}\\sum_{i=1}^{n} K\\left(\\frac{x - X_i}{h}\\right)$$ with $$K(x) = \\frac{15}{16}(1-x^2)^2 \\mathbb{1}_{|x| \\leq 1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def K(x)\n",
    "\n",
    "#def f_hat(x, h, tab_returns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448655ab",
   "metadata": {},
   "source": [
    "### Second Step : Choice of h\n",
    "\n",
    "- Tracer Graph de la densité pour different h (voir comment la densité évolue)\n",
    "- Utiliser un résultat théorique pour le h optimal (papier de recherche etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9e0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c221affa",
   "metadata": {},
   "source": [
    "### 3rd Step : Define the CDF of K and use\n",
    "\n",
    "$$\\hat{F}(x) = \\frac{1}{n}\\sum_{i=1}^{n} \\mathcal{K}\\left(\\frac{x - X_i}{h}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28c8ab",
   "metadata": {},
   "source": [
    "To define $\\mathcal{K}$ we have to primitive K.\n",
    "\n",
    "$$\n",
    "\\mathcal{K}(u) = \\begin{cases}\n",
    "0 & \\text{si } u < -1 \\\\[0.5em]\n",
    "\\frac{1}{2} + \\frac{15}{16}\\left(u - \\frac{2u^3}{3} + \\frac{u^5}{5}\\right) & \\text{si } -1 \\leq u \\leq 1 \\\\[0.5em]\n",
    "1 & \\text{si } u > 1\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0231252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def K_cdf(x):\n",
    "\n",
    "#def F_hat(x, h, tab_returns):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb2d00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8fb3b61",
   "metadata": {},
   "source": [
    "### Step 4: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9654c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_VaR(X, h, alpha, number_of_points):\n",
    "    # 1. Calculer F_hat(x) pour tous les points x\n",
    "    x, y = cumulative_kernel_density(X, h, number_of_points)\n",
    "    # x = grille de valeurs (1000 points entre min et max des rendements)\n",
    "    # y = F_hat(x) pour chaque point (valeurs de la CDF)\n",
    "    \n",
    "    # 2. Trouver l'index où y >= alpha pour la première fois\n",
    "    y_VaR = np.argmax(y >= alpha)\n",
    "    # argmax retourne l'INDEX du premier True dans le tableau booléen\n",
    "    # Exemple: si alpha=0.05, on cherche le premier point où F_hat >= 0.05\n",
    "    \n",
    "    # 3. Retourner la valeur de x correspondant à cet index\n",
    "    return x[y_VaR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669b10f",
   "metadata": {},
   "source": [
    "**b – Which proportion of price returns between January 2017 and December 2018 does exceed the VaR\n",
    "threshold defined in the previous question? Do you validate the choice of this non-parametric VaR?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0951e7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513     0.007463\n",
       "514     0.040741\n",
       "515     0.003737\n",
       "516    -0.008155\n",
       "517    -0.005719\n",
       "          ...   \n",
       "1018   -0.001481\n",
       "1019   -0.008653\n",
       "1020   -0.017955\n",
       "1021    0.038090\n",
       "1022    0.007583\n",
       "Name: return, Length: 510, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_2018 = df[df[\"date\"] >= \"2017\"].dropna().loc[:, \"return\"]\n",
    "df_2017_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d22515",
   "metadata": {},
   "source": [
    "Simply find the proportion of returns < to the VaR find and compare with the alpha. Mentionne the word coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52833dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#j'ai simplifié la fonction qu'on avait dans notr elab car une seul VaR\n",
    "def Proportion(df, VaR):\n",
    "    prop = df[df < VaR].count() / df.count()\n",
    "    return prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64d6e3",
   "metadata": {},
   "source": [
    "**Question B (Ex2, Q5 of TD2)\n",
    "Calculate the expected shortfall for the VaR calculated in question A. How is the result, compared to\n",
    "the VaR?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_beyond_VaR = df_2015_2016[df_2015_2016[\"returns\"] <= VaR_alpha]\n",
    "ES_alpha = np.mean(losses_beyond_VaR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d153ea",
   "metadata": {},
   "source": [
    "**Question C (Ex2, Q1 and Q2 of TD3)\n",
    "\n",
    "With the dataset provided for TD1 on Natixis prices, first calculate daily returns. You will then analyse\n",
    "these returns using a specific method in the field of the EVT.\n",
    "\n",
    "a – Estimate the GEV parameters for the two tails of the distribution of returns, using the estimator of\n",
    "Pickands. What can you conclude about the nature of the extreme gains and losses?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "830f98b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_loss : -0.5089715779341932\n",
      "e_gain : -0.9367427921518837\n"
     ]
    }
   ],
   "source": [
    "# Ce qu'on a fait TD3\n",
    "\n",
    "# loss\n",
    "loss = list(df[df[\"return\"] < 0][\"return\"] * -1)\n",
    "loss.sort()\n",
    "n = len(loss)\n",
    "e_loss = np.log((loss[int(n-1 - np.floor(np.log(n)) + 1)] - loss[int(n-1 - 2 * np.floor(np.log(n)) + 1)]) / (loss[int(n-1 - 2 * np.floor(np.log(n)) + 1)] - loss[int(n-1 - 4 * np.floor(np.log(n)) + 1)]))\n",
    "e_loss /= np.log(2)\n",
    "print(\"e_loss :\", e_loss)\n",
    "\n",
    "# gain\n",
    "gain = list(df[df[\"return\"] > 0][\"return\"] * -1)\n",
    "gain.sort()\n",
    "n = len(gain)\n",
    "e_gain = np.log((gain[int(n-1 - np.floor(np.log(n)) + 1)] - gain[int(n-1 - 2 * np.floor(np.log(n)) + 1)]) / (gain[int(n-1 - 2 * np.floor(np.log(n)) + 1)] - gain[int(n-1 - 4 * np.floor(np.log(n)) + 1)]))\n",
    "e_gain /= np.log(2)\n",
    "print(\"e_gain :\", e_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e066da",
   "metadata": {},
   "source": [
    "**b – Calculate the value at risk based on EVT for various confidence levels, with the assumption of iid\n",
    "returns.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2669f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
